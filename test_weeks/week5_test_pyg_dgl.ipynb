{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this work, you will use the APIs of PyG and DGL to implement some basic functions."
   ],
   "metadata": {
    "id": "AlNTfUPr23ZK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to run the following commands to install the GNN libraries (Only CPU version)."
   ],
   "metadata": {
    "id": "JaQosFNq8NdN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install  dgl -f https://data.dgl.ai/wheels/repo.html\n",
    "# !pip install torch_geometric\n",
    "# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.1+cpu.html\n"
   ],
   "metadata": {
    "id": "WFIKyZRk8WRm",
    "ExecuteTime": {
     "end_time": "2024-05-19T05:32:15.059956400Z",
     "start_time": "2024-05-19T05:32:10.167902200Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The most popular GNN models can be written as follows:\n",
    "\n",
    "$$\n",
    "h_i^{(l+1)}=\\sigma(b^{(l)}+\\sum_{j\\in\\mathcal{N}(i)}e_{ij}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "\n",
    "where $h_i^{(l+1)}$ is the output feature, $\\sigma$ is the activation function, $e_{ij}$ is the edge weight, $W^{(l)}$ is the learnable parameters, $b^{(l)\n",
    "}$ is the bias.\n",
    "\n",
    "First, you will use the PyTorch-Geometric(PyG) to implement this convolution layer."
   ],
   "metadata": {
    "id": "aDRLr_Ot6-gE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "RAQfM5GS2qlv",
    "ExecuteTime": {
     "end_time": "2024-06-01T03:05:14.872416300Z",
     "start_time": "2024-06-01T03:05:14.842846200Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m<tokenize>:30\u001B[1;36m\u001B[0m\n\u001B[1;33m    def update(self, aggr_out):\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "class PyG_conv(MessagePassing):\n",
    "  def __init__(self,in_channel,out_channel,):\n",
    "    super(PyG_conv, self).__init__(aggr='add')\n",
    "    self.in_channel = in_channel\n",
    "    self.out_channel = out_channel\n",
    "    self.W = nn.Parameter(torch.ones((in_channel, out_channel)))\n",
    "    self.b = nn.Parameter(torch.ones(out_channel))\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "    # Your code here\n",
    "     \n",
    "    # End code here\n",
    "\n",
    "  def message(x, edge_weight):\n",
    "    # Your code here\n",
    "    \n",
    "    # End code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class PyG_conv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PyG_conv, self).__init__(aggr='add', flow='source_to_target')\n",
    "        # \"Add\" aggregation (Step 5).\n",
    "        # flow='source_to_target' 表示消息从源节点传播到目标节点\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        # row, col = edge_index\n",
    "        # deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        # deg_inv_sqrt = deg.pow(-0.5)\n",
    "        # norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x,  edge_weight=edge_weight) \n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T09:23:46.895576200Z",
     "start_time": "2024-06-01T09:23:46.855122700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may run the following code to check the correctness."
   ],
   "metadata": {
    "id": "xmxHSrJkH_xe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
    "x = torch.ones((5, 8))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "conv = PyG_conv(8, 4)\n",
    "output = conv(x, edge_index, edge_weight)\n",
    "print(output)\n",
    "assert np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]])"
   ],
   "metadata": {
    "id": "ov24C3_hH-Sc",
    "ExecuteTime": {
     "end_time": "2024-06-01T09:23:53.327512100Z",
     "start_time": "2024-06-01T09:23:53.109654600Z"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object '_empty' has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m edge_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;241m6\u001B[39m)\n\u001B[0;32m      6\u001B[0m conv \u001B[38;5;241m=\u001B[39m PyG_conv(\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(output\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), [[\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m],\n\u001B[0;32m     10\u001B[0m                       [ \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m],\n\u001B[0;32m     11\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     12\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     13\u001B[0m                       [\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m]])\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[43], line 25\u001B[0m, in \u001B[0;36mPyG_conv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     16\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin(x)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Step 3: Compute normalization.\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# row, col = edge_index\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# deg = degree(col, x.size(0), dtype=x.dtype)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m \n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Step 4-5: Start propagating messages.\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    546\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 547\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    549\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "Cell \u001B[1;32mIn[43], line 30\u001B[0m, in \u001B[0;36mPyG_conv.message\u001B[1;34m(self, x_j, norm)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_j, norm):\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;66;03m# x_j has shape [E, out_channels]\u001B[39;00m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# Step 4: Normalize node features.\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnorm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m x_j\n",
      "\u001B[1;31mAttributeError\u001B[0m: type object '_empty' has no attribute 'view'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.4094e-27, 3.7162e-42, 0.0000e+00, 0.0000e+00],\n",
      "        [2.4612e-27, 1.2387e-42, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2358e-26, 6.1937e-42, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2358e-26, 6.1937e-42, 0.0000e+00, 0.0000e+00],\n",
      "        [7.4094e-27, 3.7162e-42, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 54\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mallclose(output\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), [[\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m],\n\u001B[0;32m     55\u001B[0m                       [ \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m],\n\u001B[0;32m     56\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     57\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     58\u001B[0m                       [\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m]])\n",
      "Cell \u001B[1;32mIn[8], line 54\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mallclose(output\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), [[\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m],\n\u001B[0;32m     55\u001B[0m                       [ \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m,  \u001B[38;5;241m1.\u001B[39m],\n\u001B[0;32m     56\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     57\u001B[0m                       [\u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m, \u001B[38;5;241m33.\u001B[39m],\n\u001B[0;32m     58\u001B[0m                       [\u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m, \u001B[38;5;241m17.\u001B[39m]])\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mF:\\Pycharm2023\\PyCharm 2023.2.5\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Pycharm2023\\PyCharm 2023.2.5\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Pycharm2023\\PyCharm 2023.2.5\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class CustomGNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomGNNConv, self).__init__(aggr='add')  # 使用 \"Add\" 聚合\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.W = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.b = Parameter(torch.Tensor(out_channels))\n",
    "    #     self.reset_parameters()\n",
    "    # \n",
    "    # def reset_parameters(self):\n",
    "    #     torch.nn.init.xavier_uniform_(self.W)\n",
    "    #     torch.nn.init.zeros_(self.b)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight = edge_weight):\n",
    "        # 第一步：给邻接矩阵添加自环\n",
    "        # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        # if edge_weight is not None:\n",
    "        #     self_loops_weight = torch.ones(x.size(0)).to(edge_weight.device)\n",
    "        #     edge_weight = torch.cat([edge_weight, self_loops_weight])\n",
    "        x_p = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        # 第二步：开始传播消息\n",
    "        return x_p\n",
    "\n",
    "    def message(self, x, edge_index, edge_weight):\n",
    "        # Step 3: 计算消息\n",
    "        row, col = edge_index\n",
    "        if edge_weight is None:\n",
    "            return x[col]\n",
    "        else:\n",
    "            return edge_weight.view(-1, 1) * x[col]\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Step 4: 更新节点特征\n",
    "        return aggr_out @ self.W + self.b\n",
    "\n",
    "# 示例边索引和特征\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 4], [2, 0, 2, 3, 4, 3]], dtype=torch.long)\n",
    "x = torch.ones((5, 8))  # 5 个节点，每个节点有 8 个特征\n",
    "edge_weight = 2 * torch.ones(6)  # 边权重\n",
    "from torch_geometric.data import Data\n",
    "data = Data(x=x, edge_index=edge_index)# 定义并应用自定义卷积层\n",
    "conv = CustomGNNConv(in_channels=8, out_channels=4)\n",
    "output = conv(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "print(output)\n",
    "import numpy as np\n",
    "assert np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T14:47:43.484100100Z",
     "start_time": "2024-06-02T14:34:01.090010600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (11) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Define and apply the custom convolution layer\u001B[39;00m\n\u001B[0;32m     44\u001B[0m conv \u001B[38;5;241m=\u001B[39m CustomGNNConv(in_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[5], line 25\u001B[0m, in \u001B[0;36mCustomGNNConv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     22\u001B[0m edge_index, _ \u001B[38;5;241m=\u001B[39m add_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Step 2: Start propagating messages\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    546\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 547\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    549\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "Cell \u001B[1;32mIn[5], line 32\u001B[0m, in \u001B[0;36mCustomGNNConv.message\u001B[1;34m(self, x_j, edge_weight)\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_j\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (6) must match the size of tensor b (11) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class CustomGNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomGNNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.W = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.b = Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.W)\n",
    "        torch.nn.init.zeros_(self.b)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # Step 1: Add self-loops to the adjacency matrix\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        # Step 3: Compute messages\n",
    "        if edge_weight is None:\n",
    "            return x_j\n",
    "        else:\n",
    "            return edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # Step 4: Update node features\n",
    "        return F.relu(aggr_out @ self.W + self.b)\n",
    "\n",
    "# Sample edge_index and features\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 4], [2, 0, 2, 3, 4, 3]], dtype=torch.long)\n",
    "x = torch.ones((5, 8))  # 5 nodes with 8 features each\n",
    "edge_weight = 2 * torch.ones(6)  # edge weights\n",
    "\n",
    "# Define and apply the custom convolution layer\n",
    "conv = CustomGNNConv(in_channels=8, out_channels=4)\n",
    "output = conv(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-02T14:32:48.932659300Z",
     "start_time": "2024-06-02T14:32:47.817969300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GraphConv(MessagePassing):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(GraphConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin.weight)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor):\n",
    "        # Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Start propagating messages.\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j: Tensor, norm: Tensor) -> Tensor:   \n",
    "        # Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out: Tensor):\n",
    "        # Add bias after aggregation.\n",
    "        biased = self.lin(aggr_out) + self.bias\n",
    "        return biased\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def test_basic():\n",
    "    # init test\n",
    "    in_channels = 16\n",
    "    out_channels = 32\n",
    "    conv = GraphConv(in_channels, out_channels)\n",
    "\n",
    "    # prepare input data\n",
    "    x = torch.randn(4, in_channels) # 4x16\n",
    "    edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                               [1, 0, 2, 1]], dtype=torch.long)\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    # foiward test\n",
    "    out = conv(data.x, data.edge_index)\n",
    "    assert out.size() == (4, out_channels)\n",
    "\n",
    "    # backward test\n",
    "    if torch.cuda.is_available():\n",
    "        conv = conv.cuda()\n",
    "        data = data.cuda()\n",
    "    out.mean().backward()\n",
    "    assert conv.lin.weight.grad is not None\n",
    "    assert conv.bias.grad is not None\n",
    "\n",
    "def test_reset_parameters():\n",
    "    # init test\n",
    "    in_channels = 16\n",
    "    out_channels = 32\n",
    "    conv = GraphConv(in_channels, out_channels)\n",
    "\n",
    "    # test parameter initialization\n",
    "    conv.reset_parameters()\n",
    "    assert torch.allclose(conv.bias, torch.zeros(out_channels))\n",
    "    lin_weight = conv.lin.weight\n",
    "    assert torch.allclose(lin_weight, lin_weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T02:26:58.995664200Z",
     "start_time": "2024-06-01T02:26:58.972660Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, you will implement the same functions with DGL."
   ],
   "metadata": {
    "id": "6Ou03H2BOdoE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "class DGL_conv(nn.Module):\n",
    "  def __init__(self, in_channel, out_channel):\n",
    "    self.in_channel = in_channel\n",
    "    self.out_channel = out_channel\n",
    "    #nn.Parameter将一个不可训练的tensor转换成可以训练的类型parameter，并将这个parameter绑定到这个module里面。\n",
    "    self.W = nn.Parameter(torch.ones(in_channel, out_channel)) \n",
    "    self.b = nn.Parameter(torch.ones(out_channel))\n",
    "\n",
    "  def forward(self, g, h):\n",
    "    # Your code here\n",
    "    g.update_all(fn.u_mul_e('h',self.W),fn.sum)\n",
    "    \n",
    "    \n",
    "    return h\n",
    "\n",
    "    # End code here"
   ],
   "metadata": {
    "id": "eK5wT_h9Oh6S",
    "ExecuteTime": {
     "end_time": "2024-06-01T06:54:57.223008600Z",
     "start_time": "2024-06-01T06:54:53.792735700Z"
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, you can also run the code below to check the correctness."
   ],
   "metadata": {
    "id": "D3YW_vmbT_SC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "g = dgl.graph((src, dst))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "conv = DGL_conv(8, 4)\n",
    "output = conv(g, h, edge_weight)\n",
    "import numpy as np\n",
    "assert np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]])"
   ],
   "metadata": {
    "id": "dp1e8tejUFlS",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-29T14:30:57.831643800Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test in tutorials of DGL (graph-centric)\n",
    "1. graph example\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=4, num_edges=4,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dgl\n",
    "import torch as th\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "u, v = th.tensor([0, 0, 0, 1]), th.tensor([1, 2, 3, 3])\n",
    "g = dgl.graph((u, v))\n",
    "print(g) # 图中节点的数量是DGL通过给定的图的边列表中最大的点ID推断所得出的\n",
    "g = dgl.graph((u, v), num_nodes=8)\n",
    "nx.draw(g.to_networkx(),with_labels=False)#可视化图 to_networkx()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:01:26.776437400Z",
     "start_time": "2024-05-30T12:01:25.225397300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. heterogeneous graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'disease': 3, 'drug': 3},\n",
      "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'treats', 'disease'): 1},\n",
      "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'disease', 'treats')])\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "dgl.to_networkx only supports homogeneous graphs.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDGLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(eg)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# eg.nodes['drug'].data['hv']\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m nx\u001B[38;5;241m.\u001B[39mdraw(\u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_networkx\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,with_labels\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;66;03m#可视化图\u001B[39;00m\n\u001B[0;32m     14\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\dgl\\convert.py:1697\u001B[0m, in \u001B[0;36mto_networkx\u001B[1;34m(g, node_attrs, edge_attrs)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DGLError(\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot convert a CUDA graph to networkx. Call g.cpu() first.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1695\u001B[0m     )\n\u001B[0;32m   1696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m g\u001B[38;5;241m.\u001B[39mis_homogeneous:\n\u001B[1;32m-> 1697\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DGLError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdgl.to_networkx only supports homogeneous graphs.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1698\u001B[0m src, dst \u001B[38;5;241m=\u001B[39m g\u001B[38;5;241m.\u001B[39medges()\n\u001B[0;32m   1699\u001B[0m src \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39masnumpy(src)\n",
      "\u001B[1;31mDGLError\u001B[0m: dgl.to_networkx only supports homogeneous graphs."
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "g = dgl.heterograph({\n",
    "   ('drug', 'interacts', 'drug'): (th.tensor([0, 1]), th.tensor([1, 2])),\n",
    "   ('drug', 'interacts', 'gene'): (th.tensor([0, 1]), th.tensor([2, 3])),\n",
    "   ('drug', 'treats', 'disease'): (th.tensor([1]), th.tensor([2]))\n",
    "})\n",
    "g.nodes['drug'].data['hv'] = th.ones(3, 1)\n",
    "eg = dgl.edge_type_subgraph(g, [('drug', 'interacts', 'drug'),\n",
    "                                ('drug', 'treats', 'disease')])\n",
    "print(eg)\n",
    "# eg.nodes['drug'].data['hv']\n",
    "nx.draw(g.to_networkx(),with_labels=False)#可视化图\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:01:33.170686500Z",
     "start_time": "2024-05-30T12:01:32.845685700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#将图数据放在GPU，dgl的GPU版本还不能用\n",
    "#没有安装GPU版本的，报错了，后续记得在新的虚拟环境中调好版本\n",
    "import dgl \n",
    "import torch as th\n",
    "device = th.device(\"cuda\")\n",
    "u, v = th.tensor([0, 1, 2]), th.tensor([2, 3, 4])\n",
    "g = dgl.graph((u, v))\n",
    "g.ndata['x'] = th.randn(5, 3)  # original feature is on CPU\n",
    "# g.device\n",
    "\n",
    "# cuda_g = g.to(device)  # accepts any device objects from backend framework\n",
    "# cuda_g.device()\n",
    "# cuda_g.ndata['x'].device       # feature data is copied to GPU too\n",
    "# \n",
    "# # A graph constructed from GPU tensors is also on GPU\n",
    "# u, v = u.to('cuda:0'), v.to('cuda:0')\n",
    "# g = dgl.graph((u, v))\n",
    "# g.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:01:39.605000900Z",
     "start_time": "2024-05-30T12:01:39.588997300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feat'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m linear_src \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mParameter(torch\u001B[38;5;241m.\u001B[39mFloatTensor(size\u001B[38;5;241m=\u001B[39m(node_feat_dim, out_dim)))\n\u001B[0;32m      6\u001B[0m linear_dst \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mParameter(torch\u001B[38;5;241m.\u001B[39mFloatTensor(size\u001B[38;5;241m=\u001B[39m(node_feat_dim, out_dim)))\n\u001B[1;32m----> 7\u001B[0m out_src \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m@\u001B[39m linear_src\n\u001B[0;32m      8\u001B[0m out_dst \u001B[38;5;241m=\u001B[39m g\u001B[38;5;241m.\u001B[39mndata[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeat\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m@\u001B[39m linear_dst\n\u001B[0;32m      9\u001B[0m g\u001B[38;5;241m.\u001B[39msrcdata\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout_src\u001B[39m\u001B[38;5;124m'\u001B[39m: out_src})\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\dgl\\view.py:80\u001B[0m, in \u001B[0;36mHeteroNodeDataView.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_graph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_n_repr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ntid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nodes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\dgl\\frame.py:688\u001B[0m, in \u001B[0;36mFrame.__getitem__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[0;32m    676\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the column of the given name.\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \n\u001B[0;32m    678\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    686\u001B[0m \u001B[38;5;124;03m        Column data.\u001B[39;00m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 688\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_columns\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mdata\n",
      "\u001B[1;31mKeyError\u001B[0m: 'feat'"
     ]
    }
   ],
   "source": [
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "node_feat_dim =3\n",
    "out_dim =3\n",
    "linear_src = nn.Parameter(torch.FloatTensor(size=(node_feat_dim, out_dim)))\n",
    "linear_dst = nn.Parameter(torch.FloatTensor(size=(node_feat_dim, out_dim)))\n",
    "out_src = g.ndata['feat'] @ linear_src\n",
    "out_dst = g.ndata['feat'] @ linear_dst\n",
    "g.srcdata.update({'out_src': out_src})\n",
    "g.dstdata.update({'out_dst': out_dst})\n",
    "g.apply_edges(fn.u_add_v('out_src', 'out_dst', 'out'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:01:41.417444700Z",
     "start_time": "2024-05-30T12:01:41.353575300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "for c_etype in G.cannical_etypes:\n",
    "    srctype, etype,dsttype = c_etype"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test in tutorials of PyG\n",
    "\n",
    "1. Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:59:39.382306900Z",
     "start_time": "2024-05-30T11:59:33.255669500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0,1],\n",
    "                           [1,0],\n",
    "                           [1,2],\n",
    "                           [2,1]],dtype = torch.long)\n",
    "x = torch.tensor([[-1],[0],[1]],dtype = torch.long)\n",
    "data = Data(x = x, edge_index =  edge_index.t().contiguous()) #contiguous()类似于深拷贝，如果不用这个，edge_index_t 变化，edge_index中的值也跟着变化"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:59:41.965517100Z",
     "start_time": "2024-05-30T11:59:41.892716100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDGLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# GraphConv\u001B[39;00m\n\u001B[0;32m      6\u001B[0m conv1 \u001B[38;5;241m=\u001B[39m dglnn\u001B[38;5;241m.\u001B[39mGraphConv(in_feats, out_feats)\n\u001B[1;32m----> 7\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# GATConv\u001B[39;00m\n\u001B[0;32m     10\u001B[0m conv2 \u001B[38;5;241m=\u001B[39m dglnn\u001B[38;5;241m.\u001B[39mGATConv(in_feats, out_feats, num_heads)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\graphconv.py:408\u001B[0m, in \u001B[0;36mGraphConv.forward\u001B[1;34m(self, graph, feat, weight, edge_weight)\u001B[0m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_allow_zero_in_degree:\n\u001B[0;32m    407\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (graph\u001B[38;5;241m.\u001B[39min_degrees() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m--> 408\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m DGLError(\n\u001B[0;32m    409\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere are 0-in-degree nodes in the graph, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput for those nodes will be invalid. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is harmful for some applications, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    412\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcausing silent performance regression. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    413\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAdding self-loop on the input graph by \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    414\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalling `g = dgl.add_self_loop(g)` will resolve \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    415\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe issue. Setting ``allow_zero_in_degree`` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    416\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto be `True` when constructing this module will \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    417\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msuppress the check and let the code run.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    418\u001B[0m         )\n\u001B[0;32m    419\u001B[0m aggregate_fn \u001B[38;5;241m=\u001B[39m fn\u001B[38;5;241m.\u001B[39mcopy_u(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mDGLError\u001B[0m: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run."
     ]
    }
   ],
   "source": [
    "import dgl.nn as dglnn\n",
    "in_feats = 9\n",
    "out_feats = 9\n",
    "num_heads = 5\n",
    "# GraphConv\n",
    "conv1 = dglnn.GraphConv(in_feats, out_feats)\n",
    "x = conv1(g, x)\n",
    "\n",
    "# GATConv\n",
    "conv2 = dglnn.GATConv(in_feats, out_feats, num_heads)\n",
    "x = conv2(g, x)\n",
    "\n",
    "# SAGEConv\n",
    "conv3 = dglnn.SAGEConv(in_feats, out_feats, 'mean')\n",
    "x = conv3(g, x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T12:03:06.752691800Z",
     "start_time": "2024-05-30T12:03:06.682781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (11) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# Define and apply the custom convolution layer\u001B[39;00m\n\u001B[0;32m     44\u001B[0m conv \u001B[38;5;241m=\u001B[39m CustomGNNConv(in_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, out_channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[13], line 25\u001B[0m, in \u001B[0;36mCustomGNNConv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     22\u001B[0m edge_index, _ \u001B[38;5;241m=\u001B[39m add_self_loops(edge_index, num_nodes\u001B[38;5;241m=\u001B[39mx\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Step 2: Start propagating messages\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    546\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 547\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    549\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "Cell \u001B[1;32mIn[13], line 32\u001B[0m, in \u001B[0;36mCustomGNNConv.message\u001B[1;34m(self, x_i, x_j, edge_weight)\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mx_j\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (6) must match the size of tensor b (11) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class CustomGNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomGNNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.W = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.b = Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.W)\n",
    "        torch.nn.init.zeros_(self.b)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # Step 1: Add self-loops to the adjacency matrix\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_weight):\n",
    "        # Step 3: Compute messages\n",
    "        if edge_weight is None:\n",
    "            return x_j\n",
    "        else:\n",
    "            return edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Step 4: Update node features\n",
    "        return F.relu(aggr_out @ self.W + self.b)\n",
    "\n",
    "# Sample edge_index and features\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 4], [2, 0, 2, 3, 4, 3]], dtype=torch.long)\n",
    "x = torch.ones((5, 8))  # 5 nodes with 8 features each\n",
    "edge_weight = 2 * torch.ones(6)  # edge weights\n",
    "\n",
    "# Define and apply the custom convolution layer\n",
    "conv = CustomGNNConv(in_channels=8, out_channels=4)\n",
    "output = conv(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T02:47:22.708819300Z",
     "start_time": "2024-06-01T02:47:22.520382800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.5440,  -8.8577,  -3.8916,  -9.4477],\n",
      "        [ -0.5147,  -2.9526,  -1.2972,  -3.1492],\n",
      "        [ -2.5734, -14.7628,  -6.4861, -15.7462],\n",
      "        [ -2.5734, -14.7628,  -6.4861, -15.7462],\n",
      "        [ -1.5440,  -8.8577,  -3.8916,  -9.4477]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class CustomGNNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomGNNConv, self).__init__(aggr='add')  # 使用 \"Add\" 聚合\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.W = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.b = Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.W)\n",
    "        torch.nn.init.zeros_(self.b)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        # 第一步：给邻接矩阵添加自环\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        if edge_weight is not None:\n",
    "            self_loops_weight = torch.ones(x.size(0)).to(edge_weight.device)\n",
    "            edge_weight = torch.cat([edge_weight, self_loops_weight])\n",
    "\n",
    "        # 第二步：开始传播消息\n",
    "        return self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "\n",
    "    def message(self, x, edge_index, edge_weight):\n",
    "        # Step 3: 计算消息\n",
    "        row, col = edge_index\n",
    "        if edge_weight is None:\n",
    "            return x[col]\n",
    "        else:\n",
    "            return edge_weight.view(-1, 1) * x[col]\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Step 4: 更新节点特征\n",
    "        return aggr_out @ self.W + self.b\n",
    "\n",
    "# 示例边索引和特征\n",
    "edge_index = torch.tensor([[0, 1, 1, 2, 2, 4], [2, 0, 2, 3, 4, 3]], dtype=torch.long)\n",
    "x = torch.ones((5, 8))  # 5 个节点，每个节点有 8 个特征\n",
    "edge_weight = 2 * torch.ones(6)  # 边权重\n",
    "\n",
    "# 定义并应用自定义卷积层\n",
    "conv = CustomGNNConv(in_channels=8, out_channels=4)\n",
    "output = conv(x, edge_index, edge_weight=edge_weight)\n",
    "\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T02:59:55.877130500Z",
     "start_time": "2024-06-01T02:59:55.846962300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
