{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this work, you will use the APIs of PyG and DGL to implement some basic functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8c5014770b94875"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to run the following commands to install the GNN libraries (Only CPU version)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b44d3b04137dc57e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The most popular GNN models can be written as follows:\n",
    "\n",
    "$$\n",
    "h_i^{(l+1)}=\\sigma(b^{(l)}+\\sum_{j\\in\\mathcal{N}(i)}e_{ij}h_j^{(l)}W^{(l)})\n",
    "$$\n",
    "\n",
    "where $h_i^{(l+1)}$ is the output feature, $\\sigma$ is the activation function, $e_{ij}$ is the edge weight, $W^{(l)}$ is the learnable parameters, $b^{(l)\n",
    "}$ is the bias.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3e3d4d7e436b3d2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3132688240.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[5], line 21\u001B[1;36m\u001B[0m\n\u001B[1;33m    # End code here\u001B[0m\n\u001B[1;37m                   ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "class PyG_conv(MessagePassing):\n",
    "  def __init__(self,in_channel,out_channel,):\n",
    "    super(PyG_conv, self).__init__(aggr='add')\n",
    "    self.in_channel = in_channel\n",
    "    self.out_channel = out_channel\n",
    "    self.W = nn.Parameter(torch.ones((in_channel, out_channel)))\n",
    "    self.b = nn.Parameter(torch.ones(out_channel))\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "    # Your code here\n",
    "     x_p = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "    # End code here\n",
    "\n",
    "  def message(x, edge_weight):\n",
    "    # Your code here\n",
    "    \n",
    "    # End code here"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T07:39:50.413275200Z",
     "start_time": "2024-06-03T07:39:50.410275600Z"
    }
   },
   "id": "e060eb7457d7ea4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
    "x = torch.ones((5, 8))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "conv = PyG_conv(8, 4)\n",
    "output = conv(x, edge_index, edge_weight)\n",
    "print(output)\n",
    "assert np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3218384c24c50916"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T07:43:46.743053700Z",
     "start_time": "2024-06-03T07:43:44.240123900Z"
    }
   },
   "id": "d8266d3698ad42b3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#create the class about the conv\n",
    "\n",
    "class DGL_conv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(DGL_conv, self).__init__()\n",
    "        self.input_channel = input_channels\n",
    "        self.output_channel = output_channels\n",
    "        self.W = nn.Parameter(torch.ones((input_channels,output_channels)))\n",
    "        self.b = nn.Parameter(torch.ones(output_channels))\n",
    "    def forward (self, g, h, edge_weight):\n",
    "        with g.local_scope():# local_scope 函数的目的是在这个区域进行信息传递，聚合和更新，但是并不修改原图的节点或边的特征\n",
    "            g.edata['w'] = edge_weight\n",
    "            h = torch.matmul(h, self.W)\n",
    "            # h = torch.matmul(h,g.edges['w'])\n",
    "            g.ndata['h'] = h\n",
    "            g.update_all(dgl.function.u_mul_e('h','w', 'm'), dgl.function.sum('m', 'h_sum'))\n",
    "            h_sum = g.ndata['h_sum']\n",
    "            h_message = h_sum + self.b\n",
    "            return h_message"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:52:17.405331100Z",
     "start_time": "2024-06-03T08:52:17.386350800Z"
    }
   },
   "id": "209906a07215ebc2"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17., 17., 17., 17.],\n",
      "        [ 1.,  1.,  1.,  1.],\n",
      "        [33., 33., 33., 33.],\n",
      "        [33., 33., 33., 33.],\n",
      "        [17., 17., 17., 17.]], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "g = dgl.graph((src, dst))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "# g.edata['w'] = edge_weight\n",
    "conv = DGL_conv(8, 4)\n",
    "output = conv(g, h, edge_weight)       \n",
    "print(output)\n",
    "print(np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:52:19.081845700Z",
     "start_time": "2024-06-03T08:52:18.334318900Z"
    }
   },
   "id": "6b9ed74780b7519b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n",
    "class PyG_conv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.in_channel = in_channels\n",
    "        self.out_channel = out_channels\n",
    "        self.W = nn.Parameter(torch.ones((in_channels, out_channels)))\n",
    "        self.b = nn.Parameter(torch.ones(out_channels))\n",
    "        # self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "    #     self.reset_parameters()\n",
    "    # \n",
    "    # def reset_parameters(self):\n",
    "    #     self.lin.reset_parameters()\n",
    "    #     self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        # x = self.lin(x)\n",
    "        # x = torch.matmul(x, edge_weight)\n",
    "        x = torch.matmul(x, self.W)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        # row, col = edge_index\n",
    "        # deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        # deg_inv_sqrt = deg.pow(-0.5)\n",
    "        # deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        # norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, edge_weight = edge_weight)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out = out + self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        row, col = edge_index\n",
    "        if edge_weight is None:\n",
    "            x_j = x[col]\n",
    "            return x_j\n",
    "        else:\n",
    "            x_j = edge_weight.view(-1, 1) * x_j\n",
    "            return x_j"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:52:20.538073300Z",
     "start_time": "2024-06-03T08:52:20.519064200Z"
    }
   },
   "id": "65962e31567d1d23"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 1 expected index [2, 6] to be smaller than self [5, 4] apart from dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m data \u001B[38;5;241m=\u001B[39m Data(x\u001B[38;5;241m=\u001B[39mx, edge_index\u001B[38;5;241m=\u001B[39medge_index, edge_attr\u001B[38;5;241m=\u001B[39medge_weight)\n\u001B[0;32m     38\u001B[0m conv \u001B[38;5;241m=\u001B[39m PyG_conv(\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[1;32m---> 39\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(output)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[18], line 20\u001B[0m, in \u001B[0;36mPyG_conv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     18\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# 开始消息传递\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 添加偏置\u001B[39;00m\n\u001B[0;32m     22\u001B[0m out \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\HMCAN\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    546\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 547\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    549\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "Cell \u001B[1;32mIn[18], line 26\u001B[0m, in \u001B[0;36mPyG_conv.message\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmessage\u001B[39m(\u001B[38;5;28mself\u001B[39m, x,edge_index, edge_weight):\n\u001B[1;32m---> 26\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# 消息传递，仅对有边的节点 \u001B[39;00m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m edge_weight \u001B[38;5;241m*\u001B[39m x\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Size does not match at dimension 1 expected index [2, 6] to be smaller than self [5, 4] apart from dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class PyG_conv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PyG_conv, self).__init__(aggr='add')  # 聚合函数为加法\n",
    "        self.W = torch.nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        # torch.nn.init.xavier_uniform_(self.W)  # 使用Xavier初始化\n",
    "        # torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # 线性变换\n",
    "        \n",
    "        x = torch.matmul(x, self.W)\n",
    "        # 开始消息传递\n",
    "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
    "        # 添加偏置\n",
    "        out += self.bias\n",
    "        return out\n",
    "    #重写message函数\n",
    "    def message(self, x,edge_index, edge_weight):\n",
    "        x = torch.gather(x, dim=0, index=edge_index)\n",
    "        # 消息传递，仅对有边的节点 \n",
    "        return edge_weight * x\n",
    "\n",
    "# 使用示例\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import numpy as np\n",
    "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
    "x = torch.ones((5, 8))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "conv = PyG_conv(8, 4)\n",
    "output = conv(data.x, data.edge_index, data.edge_attr)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T08:52:21.996082700Z",
     "start_time": "2024-06-03T08:52:21.383299400Z"
    }
   },
   "id": "e6cf86b8bf9768a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
    "x = torch.ones((5, 8))\n",
    "edge_weight = 2 * torch.ones(6)\n",
    "conv = PyG_conv(8, 4)\n",
    "output = conv(x, edge_index, edge_weight)\n",
    "print(output)\n",
    "assert np.allclose(output.detach().numpy(), [[17., 17., 17., 17.],\n",
    "                      [ 1.,  1.,  1.,  1.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [33., 33., 33., 33.],\n",
    "                      [17., 17., 17., 17.]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-02T16:47:15.995990600Z"
    }
   },
   "id": "ac37a4bf8950fe19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "303fe07279d26def"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
